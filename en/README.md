# Aparker

> Yet another intelligent spider.

**Note**: 
If you just want to know how to use, you can omit this page!

### Introduction
As computer technology continues to 
develop these years, more and 
more information has been published on to the internet. 
Most businesses have to be extremely sensitive to the information
published by different online information providers (like 
New York Times, etc.). However, either programming requirement
of currently available crawling system or huge cost of hiring
spider developer blocks the way of companies to gain enough 
published information. 


After massive project practice and summaries, 
Aparker, an easy, elegant, online spider, is refined 
by Zwang Team. It could crawl any web page that 
you could reach by your Chrome just by a few easy 
button-clicking settings. 

If you are not a programmer, you could use our panel for
data visualization and NLP analysis. It is well-designed and
don't worry, no coding needed! Indeed, you could even define your NLP analysis
by training our model with small amount of data. (Also
no code needed) If you are a programmer and 
hope to get your hand dirty on the other hand, 
we have APIs and SDKs for data retrieval and online/offline
NLP analysis. 

### Cases
* Searching  
    Searching system requires huge amount of data on internet.
    With Aparker, you could define a searching system of a 
    specific website by crawling all of their pages! We would 
    handle the coding of searching.
    

* Warning  
    Searching system requires huge amount of data on internet.
    With Aparker, you could define a searching system of a 
    specific website by crawling all of their pages! We would 
    handle the coding of searching.   
    

* Articles PDFs  
    Searching system requires huge amount of data on internet.
    With Aparker, you could define a searching system of a 
    specific website by crawling all of their pages! We would 
    handle the coding of searching.   

For more information, you could take a look at 
[API Docs](en/API)

### Principal of Design

### Opensource Softwares Used
Backend
* [Celery]() - For dealing the job queue
* [Flask]() - For API server
* [Requests]() - For crawling webpages
* [Redis]() - For counting epochs and instant settings
* [MongoDB]() - For saving webpages
* [ElasticSearch]() - For searching system
* [Selenium]() - For spoofing anti-spider system
* [Google V8]() - For analyzing JS
* [MariaDB]() - For saving user data
* [Zookeeper]() - For micro-service

Frontend
* [jQuery]() - Anything!
* [gin]() - Frontend template engine

### About Us

### Join Us
